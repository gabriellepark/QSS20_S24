{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a2034b1-6b68-4222-ba94-4f9ff6f06a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "151365aa-4b7a-4193-8a31-64af16b5408a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>contents</th>\n",
       "      <th>date</th>\n",
       "      <th>topics_clean</th>\n",
       "      <th>components_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Convicted Bomb Plotter Sentenced to 30 Years</td>\n",
       "      <td>PORTLAND, Oregon. – Mohamed Osman Mohamud, 23,...</td>\n",
       "      <td>2014-10-01T00:00:00-04:00</td>\n",
       "      <td>No topic</td>\n",
       "      <td>National Security Division (NSD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12-919</td>\n",
       "      <td>$1 Million in Restitution Payments Announced t...</td>\n",
       "      <td>WASHINGTON – North Carolina’s Waccamaw River...</td>\n",
       "      <td>2012-07-25T00:00:00-04:00</td>\n",
       "      <td>No topic</td>\n",
       "      <td>Environment and Natural Resources Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-1002</td>\n",
       "      <td>$1 Million Settlement Reached for Natural Reso...</td>\n",
       "      <td>BOSTON– A $1-million settlement has been...</td>\n",
       "      <td>2011-08-03T00:00:00-04:00</td>\n",
       "      <td>No topic</td>\n",
       "      <td>Environment and Natural Resources Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10-015</td>\n",
       "      <td>10 Las Vegas Men Indicted \\r\\nfor Falsifying V...</td>\n",
       "      <td>WASHINGTON—A federal grand jury in Las Vegas...</td>\n",
       "      <td>2010-01-08T00:00:00-05:00</td>\n",
       "      <td>No topic</td>\n",
       "      <td>Environment and Natural Resources Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18-898</td>\n",
       "      <td>$100 Million Settlement Will Speed Cleanup Wor...</td>\n",
       "      <td>The U.S. Department of Justice, the U.S. Envir...</td>\n",
       "      <td>2018-07-09T00:00:00-04:00</td>\n",
       "      <td>Environment</td>\n",
       "      <td>Environment and Natural Resources Division</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title  \\\n",
       "0     None       Convicted Bomb Plotter Sentenced to 30 Years   \n",
       "1  12-919   $1 Million in Restitution Payments Announced t...   \n",
       "2  11-1002  $1 Million Settlement Reached for Natural Reso...   \n",
       "3   10-015  10 Las Vegas Men Indicted \\r\\nfor Falsifying V...   \n",
       "4   18-898  $100 Million Settlement Will Speed Cleanup Wor...   \n",
       "\n",
       "                                            contents  \\\n",
       "0  PORTLAND, Oregon. – Mohamed Osman Mohamud, 23,...   \n",
       "1    WASHINGTON – North Carolina’s Waccamaw River...   \n",
       "2        BOSTON– A $1-million settlement has been...   \n",
       "3    WASHINGTON—A federal grand jury in Las Vegas...   \n",
       "4  The U.S. Department of Justice, the U.S. Envir...   \n",
       "\n",
       "                        date topics_clean  \\\n",
       "0  2014-10-01T00:00:00-04:00     No topic   \n",
       "1  2012-07-25T00:00:00-04:00     No topic   \n",
       "2  2011-08-03T00:00:00-04:00     No topic   \n",
       "3  2010-01-08T00:00:00-05:00     No topic   \n",
       "4  2018-07-09T00:00:00-04:00  Environment   \n",
       "\n",
       "                             components_clean  \n",
       "0            National Security Division (NSD)  \n",
       "1  Environment and Natural Resources Division  \n",
       "2  Environment and Natural Resources Division  \n",
       "3  Environment and Natural Resources Division  \n",
       "4  Environment and Natural Resources Division  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doj = pd.read_json(\"combined.json\", lines = True)\n",
    "\n",
    "## due to json, topics are in a list so remove them and concatenate with ;\n",
    "doj['topics_clean'] = [\"; \".join(topic) \n",
    "                      if len(topic) > 0 else \"No topic\" \n",
    "                      for topic in doj.topics]\n",
    "\n",
    "## similarly with components\n",
    "doj['components_clean'] = [\"; \".join(comp) \n",
    "                           if len(comp) > 0 else \"No component\" \n",
    "                           for comp in doj.components]\n",
    "\n",
    "## drop older columns from data\n",
    "doj = doj[['id', 'title', 'contents', 'date', 'topics_clean', \n",
    "           'components_clean']].copy()\n",
    "\n",
    "doj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96063a5f-bafd-4329-a0c7-2bc970b38ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doj_subset = doj[(doj['topics_clean'] == 'Civil Rights') | \n",
    "                 (doj['topics_clean'] == 'Hate Crimes') | \n",
    "                 (doj['topics_clean'] == 'Project Safe Childhood')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587289c1-945b-4034-878d-7a581f3d3ea7",
   "metadata": {},
   "source": [
    "# 4. Optional extra credit (2 points)\n",
    "\n",
    "You notice that the pharmaceutical kickbacks press release we analyzed in question 1 was for an indictment, and that in the original data, there's not a clear label for whether a press release outlines an indictment (charging someone with a crime), a conviction (convicting them after that charge either via a settlement or trial), or a sentencing (how many years of prison or supervised release a defendant is sentenced to after their conviction).\n",
    "\n",
    "You want to see if you can identify pairs of press releases where one press release is from one stage (e.g., indictment) and another is from a different stage (e.g., a sentencing).\n",
    "\n",
    "You decide that one way to approach is to find the pairwise string similarity between each of the processed press releases in `doj_subset`. There are many ways to do this, so Google for some approaches, focusing on ones that work well for entire documents rather than small strings.\n",
    "\n",
    "Find the top two pairs (so four press releases total)-- do they seem like different stages of the same crime or just press releases covering similar crimes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ed7342-3930-4d42-aef0-62cb374507f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b204b1f-a75b-4e58-b610-d9a09bca8d3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "107",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/qss20/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 107",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Print the top two pairs of documents with the most overlapping words\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pair, overlap \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(top_pairs, top_overlaps):\n\u001b[1;32m     32\u001b[0m    \u001b[38;5;66;03m# print(f\"The pair of documents {pair} have {overlap} overlapping words.\")\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe pair of documents\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mdoj_subset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpair\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m, doj_subset\u001b[38;5;241m.\u001b[39mloc[pair[\u001b[38;5;241m0\u001b[39m]], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhave\u001b[39m\u001b[38;5;124m'\u001b[39m, doj_subset\u001b[38;5;241m.\u001b[39mloc[overlap[\u001b[38;5;241m0\u001b[39m]],doj_subset\u001b[38;5;241m.\u001b[39mloc[overlap[\u001b[38;5;241m1\u001b[39m]], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverlapping words.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/qss20/lib/python3.11/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/qss20/lib/python3.11/site-packages/pandas/core/indexing.py:1431\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1429\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/qss20/lib/python3.11/site-packages/pandas/core/indexing.py:1381\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: AxisInt):\n\u001b[1;32m   1380\u001b[0m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/qss20/lib/python3.11/site-packages/pandas/core/generic.py:4301\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4299\u001b[0m             new_index \u001b[38;5;241m=\u001b[39m index[loc]\n\u001b[1;32m   4300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4301\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m   4304\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m loc\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/qss20/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 107"
     ]
    }
   ],
   "source": [
    "# Assuming doj_subset is your DataFrame and 'contents' is the name of the column containing the documents\n",
    "\n",
    "# Preprocess documents to create inverted indices\n",
    "word_to_docs = defaultdict(set)\n",
    "for idx, doc in enumerate(doj_subset['contents']):\n",
    "    words = set(doc.split())\n",
    "    for word in words:\n",
    "        word_to_docs[word].add(idx)\n",
    "\n",
    "# Keep track of the top two pairs of documents with most overlap\n",
    "top_pairs = [(0, 0), (0, 0)]  # Initialize with dummy pairs\n",
    "top_overlaps = [0, 0]  # Initialize with zero overlaps\n",
    "\n",
    "# Iterate through pairs of documents and calculate the intersection of their inverted indices\n",
    "for i, doc1 in enumerate(doj_subset['contents'][:-1]):\n",
    "    words_doc1 = set(doc1.split())\n",
    "    for j, doc2 in enumerate(doj_subset['contents'][i+1:], start=i+1):\n",
    "        words_doc2 = set(doc2.split())\n",
    "        intersection = len(words_doc1.intersection(words_doc2))\n",
    "        # Update top pairs if necessary\n",
    "        if intersection > top_overlaps[0]:\n",
    "            top_pairs[1] = top_pairs[0]\n",
    "            top_overlaps[1] = top_overlaps[0]\n",
    "            top_pairs[0] = (i, j)\n",
    "            top_overlaps[0] = intersection\n",
    "        elif intersection > top_overlaps[1]:\n",
    "            top_pairs[1] = (i, j)\n",
    "            top_overlaps[1] = intersection\n",
    "\n",
    "# Print the top two pairs of documents with the most overlapping words\n",
    "for pair, overlap in zip(top_pairs, top_overlaps):\n",
    "   # print(f\"The pair of documents {pair} have {overlap} overlapping words.\")\n",
    "    print(f'The pair of documents', doj_subset.loc[pair[0]], doj_subset.loc[pair[0]], 'have', doj_subset.loc[overlap[0]],doj_subset.loc[overlap[1]], 'overlapping words.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
